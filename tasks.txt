Task 1:
    1. Drop based on descriptions - Brett
    2. Drop based on completely empty - Brett
    3. Continuous: Plot feature vs target - Brett
    4. Categorical: Box plots or scatter plots - Tomás
        Bad prices are messing the whole thing.
				Removing prices over $50,000 we are removing only 1% of all cars.
				We still have many cars in very low prices.
				Features that shows trends:
					- Manufacturer
					- Fuel
					- Title status
					- Drive
					- type
					- Some states escape from the mean (AK, MT, ID, UT)
					- Some conditions as well
					- Color is not clear
                    - Size and cylinders should be in order to conclude something
        TODO: put discrete variables in correct order (size, condition, cylinders)
    5. Lat-lng heatmap - Tomás
        483,308 values within US normal range
        We can see some density information, but not so much about price distribution.
        Idea: use Target encoding using average price for a lat/long bin.


First steps: (Task 2)
    - Divide between training/testing = 0.4/0.1
    - Create Pipelines:
        1. Impute with median - scale
        2. Impute with "N/A" - one-hot encoding
        3. Impute with "N/A" - ordinal encoding - scaling
        4. Cap to 99%
        5. fuel: Impute with "gas" - one-hot encoding
        6. title_status: Impute with "clean" - one-hot encoding
        7. transmission: Impute with "automatic" - one-hot encoding
        8. scaling only
        9. target encoding
    - Create 1 ColumnTransformer
        id
            no imputation
            some form of scaling?
        region_url
            no imputation
            target encoding
            scaling
        year
            impute (median)
            scale (minmax or standard)
        manufacturer
            impute 'N/A' for missing values
            one hot encoding 
        condition
            impute with new categorical value
            ordinal encoding
            scaling
            Investigate dropping?
        cylinders
            impute with NEW categorical value, OR with the 'other' category
            ordinal encoding (what to do with 2 N/A values)
            scaling
            Investigate dropping?
        fuel
            impute with 'gas' value
            one-hot encoding
        odometer
            cap to 99% (make anything over = to 99%)
            Leave 0 values
            impute missing vals with median
            scale (standard)
        title_status
             impute with 'clean'
             one-hot encoding
        transmission
            impute with 'automatic'
            one-hot encoding
        drive
            impute with NEW category
            one-hot encoding
        size
            impute with NEW categorical value
            ordinal encoding
            scaling
            Investigate dropping?
        type
            impute with NEW categorical value
            one-hot encoding
        paint_color
            impute with NEW categorical value
            one-hot encoding
        state
            impute with NEW cateorical value
            one-hot encoding
    - Create model
    - Run cross-validation (could be a good idea to use timeSeriesSplit? sorted by id)
        

Second steps: (Task 3)
    0. Drop rows with "bad" target values (zero, too low, too high)
    	Filtering out targets above 99% helps ALOT (Ridge doesn't work without)
    	99% is better than 95%.  In fact, 99% is pretty darn perfect.
    1. Detect invalid values and replacing them with something (e.g. odometer, etc.)
        Plot histograms to easily see outliers
    2. Expoore capping of continuous variables to a maximim
        i.e. treat everything above a threshold as the same value
        capping the odometer helps A LOT
            Lowering the cap to 200,000 is MUCH better than 500,000
    3. Explore Binning
        Binning of continuous vars -> categorical variables (e.g. odometer)
        Sub-binning of categorical vars -> shorter list of categories (e.g. color)
    4. Parse url and use base as a new feature (instead of region_url)
        Which feature works better: region_url or prefix of url?
        Which encoding works bettter for region: target encoding or one-hot-encoding?
    5. One-hot encoding 'condition', 'cylinders', 'size' works better than ordinal encoding
    	OHE only 'condition' vs ordinal encoding helps
    	OHE only 'cylinders' vs ordinal encoding helps
    	OHE only 'size' vs ordinal encoding helps
    	(Dropping (all of) these columns does NOT help)
    6. Cleaning up model and manufacturer data (some kind of smart imputation) - BRETT
        TF/IDF?
    7. Add feature from url => owner or dealer ('/cto/' or '/ctd/' in URL) - TOMAS


Advanced steps: (Task 3 - optional)
    1. Try something out using the description
        TF/IDF?
    2. Create a new feature from lat/long and target encode?
